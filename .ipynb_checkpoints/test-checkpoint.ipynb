{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "indoor-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from mip import *\n",
    "import timeit\n",
    "\n",
    "from stable_baselines3 import DQN, TD3, DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d756d5",
   "metadata": {},
   "source": [
    "## Define Presets and Result File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c19f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_type = 'server' # 'server':to fix number of servers and vary users, 'user': to fix number of users and vary servers\n",
    "latency_threshold = 10\n",
    "S = 2 #number of services\n",
    "\n",
    "\n",
    "#Result file details\n",
    "if alloc_type == 'user':\n",
    "    U = 500 \n",
    "    result_file = f'allocation_results/allocation_for_user{U}_thres{latency_threshold}.csv'\n",
    "\n",
    "if alloc_type == 'server':\n",
    "    N = 50\n",
    "    result_file = f'allocation_results/allocation_for_server{N}_thres{latency_threshold}.csv'\n",
    "\n",
    "column_names = [\"user\", \"server\", \n",
    "                \"ilp_user\", \"ilp_time\",\n",
    "                \"greedy_user\", \"greedy_time\",\n",
    "                \"rl_user\", \"rl_time\",\n",
    "               ]\n",
    "result_user = pd.DataFrame(columns = column_names)\n",
    "result_user.to_csv(result_file, index=False)\n",
    "result_user = pd.read_csv(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a617124",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DQNPolicy' object has no attribute 'actor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [91], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model_rl \u001b[38;5;241m=\u001b[39m DQN\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_agents/edge_agent_thres\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatency_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model_exp = DQN.load(\"edge_agent_under_train\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model_td3 \u001b[38;5;241m=\u001b[39m \u001b[43mDDPG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrained_agents/edge_agent_thres\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlatency_threshold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m users_high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m      7\u001b[0m users_low \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;66;03m#to calculate the users numbers from action\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:806\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(data)\n\u001b[0;32m    805\u001b[0m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 806\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# put state_dicts back in place\u001b[39;00m\n\u001b[0;32m    809\u001b[0m model\u001b[38;5;241m.\u001b[39mset_parameters(params, exact_match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:138\u001b[0m, in \u001b[0;36mTD3._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_setup_model()\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_aliases\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Running mean and running var\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_batch_norm_stats \u001b[38;5;241m=\u001b[39m get_parameters_by_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning_\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:146\u001b[0m, in \u001b[0;36mTD3._create_aliases\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_aliases\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mactor_target\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mcritic\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1265\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DQNPolicy' object has no attribute 'actor'"
     ]
    }
   ],
   "source": [
    "# Dataset and models\n",
    "filename_base = 'dataset/dual_s_base.csv' #filename of data with only 1 user\n",
    "model_rl = DQN.load(f\"trained_agents/edge_agent_thres{latency_threshold}\")\n",
    "# model_exp = DQN.load(\"edge_agent_under_train\")\n",
    "model_td3 = TD3.load(f\"trained_agents/td3_thres{latency_threshold}\")\n",
    "users_high = 500\n",
    "users_low = 100 #to calculate the users numbers from action\n",
    "users_res = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-norway",
   "metadata": {},
   "source": [
    "### Utility Function to Load EUA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "focused-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add data to users\n",
    "def add_data(series): #not used now\n",
    "    random_speed = random.uniform(0,1)\n",
    "    if random_speed <= 0.3:\n",
    "        series['Speed']= 0\n",
    "    if random_speed > 0.3 and random_speed <= 0.6:   \n",
    "        series['Speed']= random.uniform(1, 2)\n",
    "    if random_speed > 0.6:\n",
    "        series['Speed'] = random.uniform(10, 20)\n",
    "    series['Direction']= random.randrange(0, 360, 10)\n",
    "    qospref = [ random.randint(1,3), random.randint(1,3) ]\n",
    "    qospref.sort()\n",
    "    series['LowQoS'] = qospref[0]\n",
    "    series['HighQoS'] = qospref[1]\n",
    "    return series\n",
    "\n",
    "#================Load Planet Lab data\n",
    "def load_planetlab():\n",
    "    #Convert to triangle\n",
    "    ldata = np.loadtxt('eua/PlanetLabData_1')[np.tril_indices(490)]\n",
    "    ldata = ldata[ ldata != 0]\n",
    "    ldata =np.unique(ldata)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    length = ldata.shape[0]\n",
    "    latency_row = 150\n",
    "    latency_col = (length//latency_row) #Global Data used\n",
    "    ldata = np.resize(ldata, latency_col*latency_row)\n",
    "    latency = ldata.reshape(latency_row,-1)\n",
    "    return latency\n",
    "\n",
    "#=================Fetch Network latency\n",
    "def fetch_network_lat(distance, latency_data):\n",
    "    rep_lat = np.random.choice(latency_data[distance], size=1, replace=True)\n",
    "    return rep_lat/1000 #convert latency to seconds\n",
    "    \n",
    "\n",
    "#===============User Data\n",
    "def load_users(num_of_users):\n",
    "    user_raw = pd.read_csv(\"eua/users.csv\")\n",
    "    user_raw = user_raw.rename_axis(\"UID\")\n",
    "    df = user_raw.sample(num_of_users)\n",
    "#     user_raw = user_raw.reset_index()\n",
    "    gdf = geopandas.GeoDataFrame(df, geometry = geopandas.points_from_xy(df.Longitude, df.Latitude), crs = 'epsg:4326')\n",
    "    user = gdf [['geometry']] #Keep Geometry column\n",
    "    user = user.to_crs(epsg=28355) #Covert the format of data\n",
    "    #Insert additional data to dataframe\n",
    "    #user = user.apply(add_data, axis=1)\n",
    "    return user\n",
    "\n",
    "#================Server Data\n",
    "def load_servers(num_of_servers):\n",
    "    server_raw = pd.read_csv(\"eua/servers.csv\")\n",
    "    server_raw = server_raw.rename_axis(\"SID\")\n",
    "    df = server_raw.sample(num_of_servers) #Sample Servers Randomly\n",
    "    gdf = geopandas.GeoDataFrame(df, geometry = geopandas.points_from_xy(df.LONGITUDE, df.LATITUDE), crs = 'epsg:4326')\n",
    "    server = gdf [['geometry']] #Keep Geometry column\n",
    "    server = server.to_crs(epsg=28355) #Cover to crs in Australian EPSG\n",
    "    def add_radius(series):\n",
    "#         radius = random.randrange(150, 250, 10)\n",
    "        radius = 150 #radus fixed to 150\n",
    "        series.geometry = series.geometry.buffer(radius)\n",
    "        #series['radius'] = radius    '''FIXED'''\n",
    "#         series['resource'] = tcomp\n",
    "        return series\n",
    "    server = server.apply(add_radius, axis = 1)\n",
    "    return server\n",
    "\n",
    "#================neighbourhood Computing\n",
    "def ngb_matrix(U, N, S): \n",
    "    #U: number of users\n",
    "    #N: number of servers\n",
    "    #S: number of services\n",
    "    # U X N matrix\n",
    "    user = load_users(U)\n",
    "    server = load_servers(N)\n",
    "    neighbourhood = np.zeros([U, N]) #matrix user(row) vs server(col)\n",
    "    network_latency = np.zeros(N) #network latency for each server\n",
    "    latency_data = load_planetlab() #load planetlad data, return matrix of bin size 150\n",
    "    \n",
    "    for u in range(0, U):\n",
    "        for n in range(0, N):\n",
    "            if server.iloc[n].geometry.contains(user.iloc[u].geometry):\n",
    "                neighbourhood[u,n]=1\n",
    "                #compute distance and assign latency\n",
    "                distance = server.iloc[n].geometry.centroid.distance(user.iloc[u].geometry)\n",
    "                rep_lat = fetch_network_lat(int(distance), latency_data) #fetch latency according to distance\n",
    "                if network_latency[n] < rep_lat:\n",
    "                    network_latency[n] = rep_lat\n",
    "                \n",
    "            else:\n",
    "                neighbourhood[u,n]=0\n",
    "    \n",
    "    service = np.zeros(U)\n",
    "    \n",
    "    #assign service to the users\n",
    "    for u in range(0, U):\n",
    "        service[u] = random.randrange(0, S, 1) #generate a random service request to the user\n",
    "        \n",
    "    #find service request in each server\n",
    "    server_service = np.zeros((N, S))\n",
    "    \n",
    "    #find the number of service request in each server\n",
    "    for n in range(0, N):\n",
    "        for u in range(0, U):\n",
    "            if neighbourhood[u][n] == 1:\n",
    "                server_service[n][int(service[u])] += 1\n",
    "                \n",
    "                \n",
    "    \n",
    "    return neighbourhood, user, server, service, server_service, network_latency\n",
    "\n",
    "#Plot the user and server dataset on the map\n",
    "def plot_data(user, server):\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "    %matplotlib inline\n",
    "\n",
    "    cbd = geopandas.read_file('eua/maps', crs = {'init': 'epsg=28355'} ) #read cbd-australia location data\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    ax.set_xlim(319400, 322100)\n",
    "    ax.set_ylim(5811900, 5813700)\n",
    "\n",
    "    user.plot(ax=ax, marker='o', color='red', markersize=20, zorder=3, label=\"users\")\n",
    "    server.plot(ax =ax, linestyle='dashed', edgecolor='green', linewidth=1, facecolor=\"none\", zorder=1)\n",
    "    server.centroid.plot(ax=ax, marker='s', color='blue', markersize=50, zorder=2, label=\"server\")\n",
    "    cbd.plot(ax=ax, color='grey', zorder=0, alpha = 0.3);\n",
    "\n",
    "    ax.set_title(\"MEC Environment(EUA): CBD Melbourne(Australia)\")\n",
    "    ax.legend(bbox_to_anchor=(1, 0), loc='lower left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-bones",
   "metadata": {},
   "source": [
    "## Load data for single user execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "gorgeous-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_server_state(num_server):\n",
    "    df = pd.read_csv(filename_base)\n",
    "    \n",
    "#     df['ram'] = df['ram'].div(1000).round(0).astype(int)\n",
    "#     df['workload_cpu'] = df['workload_cpu'].div(10).round(0).astype(int)\n",
    "    df['workload_gpu'] = df['workload_gpu'].multiply(1/80).round(0).astype(int) #round gpu workload\n",
    "#     df['users_yolo'] = df['users_yolo'].div(100).round(0).astype(int)\n",
    "#     df['users_mnet'] = df['users_mnet'].div(100).round(0).astype(int)\n",
    "    \n",
    "    \n",
    "    #get unique data in set\n",
    "    ram = df.ram.unique()\n",
    "    cores = df.cores.unique()\n",
    "    workload_cpu = df.workload_cpu.unique()\n",
    "\n",
    "    \n",
    "    server_state = []\n",
    "    gamma = []\n",
    "    \n",
    "    for s_id in range(num_server):\n",
    "        #generate unique state\n",
    "        gram = np.random.choice(ram, 1)[0]\n",
    "        gcores = np.random.choice(cores, 1)[0]\n",
    "        gwl_c = np.random.choice(workload_cpu, 1)[0]\n",
    "    \n",
    "        \n",
    "       \n",
    "        #fetch gamma for the state\n",
    "        fetch_state = df.loc[ (df['ram'] == gram) & (df['cores']== gcores) & (df['workload_cpu']==gwl_c) ]\n",
    "       \n",
    "        gwl_g = fetch_state.sample().iloc[0]['workload_gpu'] #fetch workload randmoly\n",
    "        fetch_time = fetch_state.loc[ (df['workload_gpu'] == gwl_g) ]\n",
    "        \n",
    "        time_yolo = fetch_time['time_yolo'].mean() #average of time for particular state\n",
    "        time_mnet = fetch_time['time_mnet'].mean()\n",
    "        \n",
    "        gs1 = server_service[s_id][0] #assignt the state according to service request to each server\n",
    "        gs2 = server_service[s_id][1] \n",
    "        server_state.append( [gram, gcores, gwl_c, gwl_g, gs1, gs2] )\n",
    "        \n",
    "        gamma.append((time_yolo, time_mnet)) #append the gamma value of each server\n",
    "    \n",
    "    return server_state, gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328fac3d",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb670115",
   "metadata": {},
   "source": [
    "### ILP Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "contrary-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ilp_algo():\n",
    "    ## ===================================ILP with python mip\n",
    "    # >> solver_name=GRB\n",
    "    # >> Currently using CBC\n",
    "    I = range(U) #user\n",
    "    J = range(N) #server\n",
    "\n",
    "    alloc = Model(sense=MAXIMIZE, name=\"alloc\", solver_name=CBC)\n",
    "\n",
    "    def coverage(user_ix, server_ix):\n",
    "        if ngb[user_ix][server_ix]==1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    #U: num of users, N: num of servers\n",
    "    x = [[ alloc.add_var(f\"x{i}{j}\", var_type=BINARY) for j in J] for i in I]\n",
    "\n",
    "    #Objective Equation\n",
    "    alloc.objective = xsum( x[i][j]  for i in I for j in J )\n",
    "\n",
    "    #1 .Coverage Constraint\n",
    "    for i in I:\n",
    "        for j in J:        \n",
    "                if not coverage(i,j):\n",
    "                    alloc += x[i][j] == 0\n",
    "\n",
    "    #2. User allocation to single server constrain\n",
    "    for i in I:\n",
    "        alloc += xsum( x[i][j] for j in J ) <=1\n",
    "\n",
    "    #3. Latency Constraint\n",
    "    for j in J:\n",
    "        alloc += xsum( gamma[j][int(service[i])]*x[i][j] for i in I ) <=latency_threshold-network_latency[j] \n",
    "\n",
    "    #alloc.write(\"test-model.lp\")\n",
    "\n",
    "    #===========Start Optimization=========\n",
    "    alloc.optimize(max_seconds=25)\n",
    "\n",
    "    #==========ILP Ends here\n",
    "    #print(f\"Number of Solutions:{qoe.num_solutions}\")\n",
    "    ilp_allocation = [ (i,j) for i in I for j in J if x[i][j].x >= 0.99]\n",
    "\n",
    "    #print(f\"Number of Solutions:{qoe.num_solutions}\")\n",
    "    #print(f\"Objective Value:{qoe.objective_value}\")\n",
    "    allocated_num_users = len(ilp_allocation)\n",
    "    print(\"ILP Allocated Num of Users: {}\".format(allocated_num_users))\n",
    "    # selected.sort()\n",
    "    return ilp_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f45173",
   "metadata": {},
   "source": [
    "### RL Allocation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "coastal-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "def rl_algo():\n",
    "    #for each server find the number of possible users using model\n",
    "    server_capacity = np.zeros((N, S))\n",
    "    for server_id in range(N):\n",
    "        state = server_state[server_id]\n",
    "#         if model_type == 'lin':\n",
    "        action = model_rl.predict(np.array(state), deterministic=True)\n",
    "#         if model_type == 'exp':\n",
    "#             action = model_exp.predict(np.array(state), deterministic=True)\n",
    "        u1 = action[0]//5 + 1\n",
    "        u2 = (action[0]+1) - (u1-1)*5\n",
    "        server_capacity[server_id][0] = u1*100 #model output\n",
    "        server_capacity[server_id][1] = u2*100 #model output\n",
    "    \n",
    "    #sort with number of servers per user\n",
    "    col1 = np.array([np.sum(ngb,axis=1)])\n",
    "    col2 = np.array([np.arange(U)])\n",
    "    sorted_ngb = np.concatenate((ngb, col1.T, col2.T), axis=1) #add rowsum and index column\n",
    "    sorted_ngb = sorted_ngb[np.argsort(sorted_ngb[:, N])] #sort the rows based on rowsum column\n",
    "\n",
    "    #allocation heuristic\n",
    "    #run allocation algorithm\n",
    "    rl_allocation = []\n",
    "\n",
    "    for i in range(U):\n",
    "        server_list = np.where(sorted_ngb[i, :N] == 1)[0] #get the list of server to which user is connected\n",
    "\n",
    "        if len(server_list) == 0: #skip users with no server\n",
    "            continue\n",
    "        \n",
    "        ser = int(service[i]) #which service user is requesting\n",
    "        choosen_server = server_list[np.argmax(server_capacity[server_list, ser])] #find the id of choosen server\n",
    "        \n",
    "        \n",
    "        if  server_capacity[choosen_server][ser] > 0: #assigning user to choosen_server\n",
    "            server_capacity[choosen_server][ser] -= 1 #decrement the server capacity\n",
    "\n",
    "            rl_allocation.append( (int(sorted_ngb[i, N+1]), choosen_server) ) #(user, server) alloc pair\n",
    "    print('RL Num of allocation: {}'.format(len(rl_allocation)))\n",
    "\n",
    "    return rl_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "def td3_algo():\n",
    "    #for each server find the number of possible users using model\n",
    "    server_capacity = np.zeros((N, S))\n",
    "    for server_id in range(N):\n",
    "        state = server_state[server_id]\n",
    "#         if model_type == 'lin':\n",
    "        action = model_td3.predict(np.array(state), deterministic=True)\n",
    "#         if model_type == 'exp':\n",
    "#             action = model_exp.predict(np.array(state), deterministic=True)\n",
    "        u1 = action[0]//5 + 1\n",
    "        u2 = (action[0]+1) - (u1-1)*5\n",
    "        server_capacity[server_id][0] = u1*100 #model output\n",
    "        server_capacity[server_id][1] = u2*100 #model output\n",
    "    \n",
    "    #sort with number of servers per user\n",
    "    col1 = np.array([np.sum(ngb,axis=1)])\n",
    "    col2 = np.array([np.arange(U)])\n",
    "    sorted_ngb = np.concatenate((ngb, col1.T, col2.T), axis=1) #add rowsum and index column\n",
    "    sorted_ngb = sorted_ngb[np.argsort(sorted_ngb[:, N])] #sort the rows based on rowsum column\n",
    "\n",
    "    #allocation heuristic\n",
    "    #run allocation algorithm\n",
    "    rl_allocation = []\n",
    "\n",
    "    for i in range(U):\n",
    "        server_list = np.where(sorted_ngb[i, :N] == 1)[0] #get the list of server to which user is connected\n",
    "\n",
    "        if len(server_list) == 0: #skip users with no server\n",
    "            continue\n",
    "        \n",
    "        ser = int(service[i]) #which service user is requesting\n",
    "        choosen_server = server_list[np.argmax(server_capacity[server_list, ser])] #find the id of choosen server\n",
    "        \n",
    "        \n",
    "        if  server_capacity[choosen_server][ser] > 0: #assigning user to choosen_server\n",
    "            server_capacity[choosen_server][ser] -= 1 #decrement the server capacity\n",
    "\n",
    "            rl_allocation.append( (int(sorted_ngb[i, N+1]), choosen_server) ) #(user, server) alloc pair\n",
    "    print('RL Num of allocation: {}'.format(len(rl_allocation)))\n",
    "\n",
    "    return rl_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1b8ff",
   "metadata": {},
   "source": [
    "### Nearest Neighbourhood Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9398111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algo():\n",
    "    server_capacity = np.zeros(N)\n",
    "    rl_allocation = []\n",
    "    for user_id in range(U):\n",
    "        server_ngb_list = np.where(ngb[user_id, :N] == 1)[0] #get the list of server to which user is connected\n",
    "        if len(server_ngb_list) == 0: #ignore the users which are not under any servers\n",
    "            continue \n",
    "    \n",
    "        #find the distance to each users in the server_ngb_list\n",
    "        dist_list = np.array([ server_ngb_list, [server.iloc[i]['geometry'].centroid.distance(user.iloc[user_id]['geometry']) for i in server_ngb_list] ])\n",
    "        # sorted list of servers based on the distance from users\n",
    "        sorted_distance_list = dist_list[ :, dist_list[1].argsort()]\n",
    "        #get the list of servers arranged in least to max distance\n",
    "        server_list = sorted_distance_list[0].astype(int)\n",
    "        \n",
    "        lat = 0\n",
    "        for server_id in server_list:\n",
    "            lat = gamma[server_id][int(service[user_id])]\n",
    "            if server_capacity[server_id]+lat <= latency_threshold-network_latency[server_id]:\n",
    "                server_capacity[server_id] += lat #increment the server_capacity of server\n",
    "                rl_allocation.append( (user_id, server_id) ) #(user, server) alloc pair\n",
    "                break\n",
    "    \n",
    "    print('Greedy-Ngb Num of allocation: {}'.format(len(rl_allocation)))\n",
    "    return rl_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-development",
   "metadata": {},
   "source": [
    "# main(): Iterative Loop to generate results for various user server configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "careful-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "if alloc_type == 'user':\n",
    "    for N in range(20, 100, 20):\n",
    "    #     for N in range(20, 100, 20):\n",
    "        for epoch in range(50):\n",
    "            print(\"User:\", U, 'Server:', N, 'Epoch:', epoch)\n",
    "    #             U = 50 #Number of users #Define U, N and ngb Matrix\n",
    "    #             N = 10 #Number of Servers\n",
    "            ngb, user, server, service, server_service, network_latency = ngb_matrix(U, N, S) #generate server and user from EUA data #determine neighbourhood matrix\n",
    "            server_state, gamma = generate_server_state(N) #assign state and gamma for each user\n",
    "\n",
    "            #=======ILP starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_ilp = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            ilp_aloc = ilp_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_ilp = stop - start\n",
    "            #========ILP ends\n",
    "\n",
    "            #=======Greedy starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_greedy = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            greedy_aloc = greedy_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_greedy = stop - start\n",
    "            #========Greedy ends\n",
    "\n",
    "            #=======RL starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_rl = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            rl_aloc = rl_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_rl = stop - start\n",
    "            #========RL_linear ends\n",
    "\n",
    "            #=======td3 starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_rl = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            td3_aloc = td3_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_td3 = stop - start\n",
    "            #========RL_linear ends\n",
    "\n",
    "            #========Store results to file\n",
    "            to_append = [U, N,\n",
    "                         len(ilp_aloc), execution_time_ilp,\n",
    "                         len(greedy_aloc), execution_time_greedy,\n",
    "                         len(rl_aloc), execution_time_rl,\n",
    "                         len(td3_aloc), execution_time_td3,\n",
    "                        ] \n",
    "            dseries = pd.Series(to_append, index = result_user.columns)\n",
    "            result_user = result_user.append(dseries, ignore_index=True)\n",
    "            print(\"epoch:\", epoch)\n",
    "    result_user.to_csv(result_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "lovely-river",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>server</th>\n",
       "      <th>ilp_user</th>\n",
       "      <th>ilp_time</th>\n",
       "      <th>greedy_user</th>\n",
       "      <th>greedy_time</th>\n",
       "      <th>rl_user</th>\n",
       "      <th>rl_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user, server, ilp_user, ilp_time, greedy_user, greedy_time, rl_user, rl_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f38194c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------\n",
      "User: 100 Server: 50 Epoch: 0\n",
      "ILP Allocated Num of Users: 81\n",
      "Greedy-Ngb Num of allocation: 81\n",
      "RL Num of allocation: 81\n",
      "epoch: 0\n",
      "\n",
      "---------------------------------------\n",
      "User: 200 Server: 50 Epoch: 0\n",
      "ILP Allocated Num of Users: 150\n",
      "Greedy-Ngb Num of allocation: 150\n",
      "RL Num of allocation: 150\n",
      "epoch: 0\n",
      "\n",
      "---------------------------------------\n",
      "User: 300 Server: 50 Epoch: 0\n",
      "ILP Allocated Num of Users: 258\n",
      "Greedy-Ngb Num of allocation: 253\n",
      "RL Num of allocation: 260\n",
      "epoch: 0\n",
      "\n",
      "---------------------------------------\n",
      "User: 400 Server: 50 Epoch: 0\n",
      "ILP Allocated Num of Users: 314\n",
      "Greedy-Ngb Num of allocation: 297\n",
      "RL Num of allocation: 328\n",
      "epoch: 0\n",
      "\n",
      "---------------------------------------\n",
      "User: 500 Server: 50 Epoch: 0\n",
      "ILP Allocated Num of Users: 415\n",
      "Greedy-Ngb Num of allocation: 393\n",
      "RL Num of allocation: 427\n",
      "epoch: 0\n"
     ]
    }
   ],
   "source": [
    "if alloc_type == 'server': #server fix vary number of users\n",
    "    for U in range(100, 600, 100):\n",
    "        for epoch in range(1):\n",
    "            print(\"\\n---------------------------------------\")\n",
    "            print(\"User:\", U, 'Server:', N, 'Epoch:', epoch)\n",
    "    #             U = 50 #Number of users #Define U, N and ngb Matrix\n",
    "    #             N = 10 #Number of Servers\n",
    "            ngb, user, server, service, server_service, network_latency = ngb_matrix(U, N, S) #generate server and user from EUA data #determine neighbourhood matrix\n",
    "            server_state, gamma = generate_server_state(N) #assign state and gamma for each user\n",
    "\n",
    "            #=======ILP starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_ilp = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            ilp_aloc = ilp_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_ilp = stop - start\n",
    "            #========ILP ends\n",
    "\n",
    "            #=======Greedy starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_greedy = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            greedy_aloc = greedy_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_greedy = stop - start\n",
    "            #========Greedy ends\n",
    "\n",
    "            #=======RL_linear starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_rl = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            rl_aloc = rl_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_rl = stop - start\n",
    "            #========RL_linear ends\n",
    "\n",
    "\n",
    "           #=======td3 starts\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            execution_time_rl = 0\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            td3_aloc = td3_algo() #call ILP algorithm\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            execution_time_td3 = stop - start\n",
    "            #========RL_linear ends\n",
    "\n",
    "            #========Store results to file\n",
    "            to_append = [U, N,\n",
    "                         len(ilp_aloc), execution_time_ilp,\n",
    "                         len(greedy_aloc), execution_time_greedy,\n",
    "                         len(rl_aloc), execution_time_rl,\n",
    "                         len(td3_aloc), execution_time_td3,\n",
    "                        ] \n",
    "            dseries = pd.Series(to_append, index = result_user.columns)\n",
    "            result_user = result_user.append(dseries, ignore_index=True)\n",
    "            print(\"epoch:\", epoch)\n",
    "    result_user.to_csv(result_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "098a55ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>server</th>\n",
       "      <th>ilp_user</th>\n",
       "      <th>ilp_time</th>\n",
       "      <th>greedy_user</th>\n",
       "      <th>greedy_time</th>\n",
       "      <th>rl_user</th>\n",
       "      <th>rl_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.131357</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.007920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.120040</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.007678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.123697</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.016144</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.007986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.105348</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.007380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>200.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.395905</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.030647</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.007697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>300.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.354603</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.045962</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>400.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.600479</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.055001</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.008886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>25.526578</td>\n",
       "      <td>393.0</td>\n",
       "      <td>0.074522</td>\n",
       "      <td>427.0</td>\n",
       "      <td>0.009412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  server  ilp_user   ilp_time  greedy_user  greedy_time  rl_user  \\\n",
       "0    100.0    50.0      80.0   0.131357         80.0     0.015563     80.0   \n",
       "1    100.0    50.0      89.0   0.120040         89.0     0.016793     89.0   \n",
       "2    100.0    50.0      87.0   0.123697         87.0     0.016144     87.0   \n",
       "3    100.0    50.0      72.0   0.137681         72.0     0.013875     72.0   \n",
       "4    100.0    50.0      80.0   0.122100         80.0     0.015711     80.0   \n",
       "..     ...     ...       ...        ...          ...          ...      ...   \n",
       "221  100.0    50.0      81.0   0.105348         81.0     0.015634     81.0   \n",
       "222  200.0    50.0     150.0   0.395905        150.0     0.030647    150.0   \n",
       "223  300.0    50.0     258.0   0.354603        253.0     0.045962    260.0   \n",
       "224  400.0    50.0     314.0   0.600479        297.0     0.055001    328.0   \n",
       "225  500.0    50.0     415.0  25.526578        393.0     0.074522    427.0   \n",
       "\n",
       "      rl_time  \n",
       "0    0.007920  \n",
       "1    0.007678  \n",
       "2    0.007591  \n",
       "3    0.007632  \n",
       "4    0.007986  \n",
       "..        ...  \n",
       "221  0.007380  \n",
       "222  0.007697  \n",
       "223  0.008416  \n",
       "224  0.008886  \n",
       "225  0.009412  \n",
       "\n",
       "[226 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-vessel",
   "metadata": {},
   "source": [
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
